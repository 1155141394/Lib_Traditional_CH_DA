{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad381c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1efHsY16pxK0lBD2gYCgCTnv1Swstq771\n",
      "To: C:\\Users\\lenovo\\data.zip\n",
      "100%|██████████| 1.88G/1.88G [01:41<00:00, 18.5MB/s]\n",
      "D:\\anaconda3\\lib\\site-packages\\ckiptagger\\model_ws.py:106: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "D:\\anaconda3\\lib\\site-packages\\ckiptagger\\model_pos.py:56: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "D:\\anaconda3\\lib\\site-packages\\ckiptagger\\model_ner.py:57: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n"
     ]
    }
   ],
   "source": [
    "from ckiptagger import data_utils, construct_dictionary, WS, POS, NER\n",
    "data_utils.download_data_gdown(\"./\") # gdrive-ckip\n",
    "# 使用 GPU：\n",
    "#    1. 安裝 tensorflow-gpu (請見安裝說明)\n",
    "#    2. 設定 CUDA_VISIBLE_DEVICES 環境變數，例如：os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#    3. 設定 disable_cuda=False，例如：ws = WS(\"./data\", disable_cuda=False)\n",
    "# 使用 CPU：\n",
    "ws = WS(\"./data\")\n",
    "pos = POS(\"./data\")\n",
    "ner = NER(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a2f902e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from itertools import chain\n",
    "\n",
    "year = 1952\n",
    "\n",
    "while year < 1986:\n",
    "    try:\n",
    "        # test.txt 是我们需要读入的繁体文本，如果遇到无法解码的错误，用errors跳过\n",
    "        f = open('./twt_text/' + str(year) + '.txt', encoding='utf-8', errors=\"ignore\")\n",
    "    except:\n",
    "        year += 1\n",
    "        continue\n",
    "\n",
    "    sentences = ''\n",
    "    for line in f.readlines():\n",
    "        line = re.sub('\\n','',line)  #去掉列表中每一个元素的换行符\n",
    "        line = re.sub('[a-zA-Z0-9]','',line) #去掉数字，字母\n",
    "        sentences += line\n",
    "\n",
    "    sentence_list = re.split(r'[，,。.]', sentences) #获得句子的list\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    word_sentence_list = ws(\n",
    "        sentence_list,\n",
    "        # sentence_segmentation = True, # To consider delimiters\n",
    "        # segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\"}), # This is the defualt set of delimiters\n",
    "        # recommend_dictionary = dictionary1, # words in this dictionary are encouraged\n",
    "        # coerce_dictionary = dictionary2, # words in this dictionary are forced\n",
    "    )\n",
    "\n",
    "    pos_word_sentence_list = pos(word_sentence_list)\n",
    "\n",
    "    word_list = list(chain.from_iterable(word_sentence_list))\n",
    "    \n",
    "    pos_word_list = list(chain.from_iterable(pos_word_sentence_list))\n",
    "\n",
    "    # 分词后用空格隔开每个单词\n",
    "    word_string = ''\n",
    "    for j in range(len(word_list)):\n",
    "        if pos_word_list[j] == 'Nb' and len(word_list[j]) != 1 and word_list[j] != '中共':\n",
    "            word_string += word_list[j] + ' '\n",
    "\n",
    "\n",
    "\n",
    "    wc = WordCloud(\n",
    "      height=300,\n",
    "      width=500,\n",
    "      background_color='white',        #   背景顏色\n",
    "      max_words=30,                    #  最大分詞數量\n",
    "      mask=None,                       #   背景圖片\n",
    "      max_font_size=None,              #   顯示字體的最大值\n",
    "      font_path='./KAIU.TTF',          # 若為中文則需引入中文字型(.TTF)\n",
    "      random_state=None,               #   隨機碼生成各分詞顏色\n",
    "      prefer_horizontal=0.9)           #   調整分詞中水平和垂直的比例\n",
    "    wc.generate(word_string) \n",
    "    wc.to_file('./tianwentai_Nb_cloud/'+ str(year) + '.png') \n",
    "    year += 1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28646780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
